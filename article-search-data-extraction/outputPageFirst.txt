Check for
Updates.

Generating Diverse Code Explanations
using the GPT-3 Large Language Model

Stephen MacNeil
stephen.macneil@temple.edu
Temple University
Philadelphia, PA, USA

Seth Bernstein
seth.bernstein@temple.edu
Temple University
Philadelphia, PA, USA

KEYWORDS

large language models, natural language processing, code explana-
tions, computer science education

ACM Reference Format:

Stephen MacNeil, Andrew Tran, Dan Mogil, Seth Bernstein, Erin Ross,
and Ziheng Huang. 2022. Generating Diverse Code Explanations using the
GPT-3 Large Language Model. In Proceedings of the 2022 ACM Conference
on International Computing Education Research V.2 (ICER 2022), August 7-11,
2022, Lugano and Virtual Event, Switzerland. ACM, New York, NY, USA,
3 pages. https://doi.org/10.1145/3501709.3544280

1 ABSTRACT

Good explanations are essential to efficiently learning introductory
rogramming concepts [10]. To provide high-quality explanations
at scale, numerous systems automate the process by tracing the
execution of code [8, 12], defining terms [9], giving hints [16],
and providing error-specific feedback [10, 16]. However, these ap-
roaches often require manual effort to configure and only explain
a single aspect of a given code segment. Large language models
(LLMs) are also changing how students interact with code [7]. For
example, Github’s Copilot can generate code for programmers [4],
eading researchers to raise concerns about cheating [7]. Instead,
our work focuses on LLMs’ potential to support learning by explain-
ing numerous aspects of a given code snippet. This poster features
a systematic analysis of the diverse natural language explanations
that GPT-3 can generate automatically for a given code snippet. We
resent a subset of three use cases from our evolving design space
of AI Explanations of Code.

2 USE CASES

To understand the types of explanations GPT-3 [2] can generate,
we issued over 700 prompts across numerous code snippets. An
example prompt and resulting explanation is shown in Figure 1.
We discovered eight explanation types and Figure 2 includes three

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the owner/author(s).

ICER 2022, August 7-11, 2022, Lugano and Virtual Event, Switzerland

© 2022 Copyright held by the owner/author(s).

ACM ISBN 978-1-4503-9195-5/22/08.

https://doi.org/10.1145/3501709.3544280

Andrew Tran
andrew.tran10@temple.edu

Temple University
Philadelphia, PA, USA

Erin Ross
erinross@temple.edu
Temple University
Philadelphia, PA, USA

37

Dan Mogil
daniel.mogil@temple.edu
Temple University
Philadelphia, PA, USA

Ziheng Huang
z8huang@ucsd.edu
University of California—San Diego
La Jolla, CA, USA

explanation types to illustrate the explanatory power of GPT-3. The
additional types include: 1) tracing the execution of code, 2) fixing
bugs and explaining how they were fixed, 3) generating analogies
to real world settings, 4) listing relevant programming concepts,
and 5) predicting the console output.

Prompt

#Give areal world analogy for thiscode < Directions (explanation type)

public static void main(String[] args) { < Code Snippet

for(inti=T;i<=3;i++){
for(int j=1;j<=3;j++){
System.out.printin(i+" "+j);

Explanation

e -

Figure 1: A prompt and explanation based on analogy.

Q

2.1 Analyzing and explaining time complexity

Instructors rate time complexity as the most difficult programming
topic [17]. However, understanding time complexity is important [6,
13] because it facilitates decision-making so students choose an
appropriate algorithm for a given problem. This use case shows
GPT-3 can identify and explain time complexity.

2.2 Identifying common mistakes made by
beginner programmers

Commonality exists in how students solve programming prob-
lems [15] and the mistakes they make [1, 11]. Pedagogical tech-
niques, such as the ‘muddiest point” highlight these common and
most confusing concepts [3, 14]. GPT-3 can automatically create
a checklist of common mistakes students might make regarding a
given code snippet.
